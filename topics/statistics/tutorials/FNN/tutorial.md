---
layout: tutorial_hands_on

title: Introduction to feedforward neural networks (FNN)
zenodo_link: https://zenodo.org/record/4477881
questions:
- What is a feedforward neural network (FNN)?
- What are some applications of FNN?
objectives:
- Understand the inspiration for neural networks
- Learn various activation functions, and classification/regression problems solved by neural networks
- Discuss various cost/loss functions and the backpropagation algorithm
- Learn how to create a neural network using Galaxy's deep learning tools
- Solve a regression problem using Boston housing dataset via FNN in Galaxy
requirements:
  -
    type: internal
    topic_name: statistics
    tutorials:
      - intro_deep_learning
time_estimation: 2H
contributors:
- kxk302
---

# Introduction
{:.no_toc}

<!-- This is a comment. -->

Artificial neural networks are a machine learning discipline roughly inspired by how neurons in a
human brain work. In the past decade, there has been a huge resurgence of neural networks thanks
to the vast availability of data and enormous increases in computing capacity (Successfully
training complex neural networks in some domains requires lots of data and compute capacity). There
are various types of neural networks (Feedforward, recurrent, etc). In this tutorial, we discuss
feedforward neural networks (FNN), which have been successfully applied to pattern classification, 
clustering, regression, association, optimization, control, and forecasting ({% cite JainEtAl %}. 
We will discuss biological neurons that inspired artificial neural networks, review activation 
functions, classification/regression problems solved by neural networks, and the backpropagation 
learning algorithm. Finally, we construct a FNN to solve a regression problem using Boston housing 
dataset. 

> ### Agenda
>
> In this tutorial, we will cover:
>
> 1. TOC
> {:toc}
>
{: .agenda}

# Inspiration for artificial neural networks

A neuron is a special biological cell with information processing ability ({% cite JainEtAl %}). 
Figure 1 shows a biological neuron. It has a cell body and two outreaching tree-like branches: 
axon and denderites. A neuron receives signals from other neurons through its denderites, and 
transmits signals generated by its cell body to other neurons via its axon. A synapse is a place 
of contact between two neurons, an axon strand of one neuron and a denderite strand of another 
neuron. A synapse can either enhance or inhibit the signal that passes through it. Learning occurs 
by changing the effectiveness of synapse. If the signals received exceeds a threshold, the neuron 
*fires*, i.e. it transmits a signal to other neurons. If not, it will not fire.       

![Sketch of a biological neuron and its components](../../images/FNN_bio_neuron.png "A biological neuron ({% cite JainEtAl %})")

Celebral cortex, the outter most layer of the brain, is a sheet of neurons about 2 to 3 mm thick, 
with a surface area of about 2,200 $$ cm^{2} $$. Celebral cortex has about $$ 10^{11} $$ neurons.
Each neuron is connected to $$ 10^{3} to 10^{4} $$ neurons. Hence, a human brain has around 
 $$ 10^{14} to 10^{15}$$ connections. Neurons communicate by a short train of signals, usually 
milliseconds in duration. The frequency in which the signals are transmitted can be up to several 
hundred Hertz, which is millions of times slower than an electronic circuit. However, complex tasks, 
such as face recognition are made within a few hundred milliseconds. This implies that computation 
involved cannot take more than 100 serial steps, i.e., brain runs parallel programs that are about 
100 steps long for such complex perceptual tasks. The amount of information sent from one neuron to 
another is also very small. This implies that critical information is not transmitted directly, but 
is captured by the interconnections. What enables slow computing elements in the brain to perfrom 
complex tasks so quickly is the distributed computation and representation nature of the brain ({% cite JainEtAl %}). 

# Perceptron

Perceptron ({% cite Rosenblatt %}) is the oldest neural network still in use today. Its a form of a 
feedforward neural network, in which the connections between the nodes do not form a loop. It accepts 
multiple inputs, each input is multiplied by a weight, and the products are added up. The weights 
simulate the role of synapse in biological neurons (to enhance or inhibit a signal). A *bias* value 
is then added to the result before it is passed to an *activation function*. An activation function 
simulates the neuron firing or not. For example in a *binary step* activation function, if the sum of 
weighted inputs and bias is greater than zero, the neuron output is 1 (it fires). Else, the neuron 
output is 0 (it does not fire). Bias allows us to shift the activation function.     

$$ f(x) =
\left\{
	\begin{array}{ll}
		1  & \mbox{if } \boldsymbol{x} \cdot \boldsymbol{w} + b \geq 0 \\
		0  & \mbox{otherwise } 
	\end{array}
\right.
$$

Figure 2 shows a Perceptron, a single layer FNN, where the input is 3 dimensional (input layer has 
3 nodes), and output is 1 dimensional (output layer has 1 node).

![Neurons forming the input and output layers of a single layer feedforward neural network](../../images/FFNN_no_hidden.png "A perceptron")

In supervised learning, we are given a set of input-output pairs, called the *training 
set*. Given the training set, the learning algorithm (iteratively) adjusts the model
parameters (weights and biases), so that the model can accurately map inputs to outputs.
The learning algorithm for Perceptron is very simple and reduces the weights (via a
small learning rate multiplier) if the predcited output is more than the expected output
and increases them otherwise ({% cite Rosenblatt %}).

Minsky and Papert showed that a single layer FNN cannot solve problems in which the data is not 
linearly separable, such as the XOR problem ({% cite Newell780 %}). Adding one (or more) hidden 
layers to FNN enables it to solve problems in which data is non-linearly separable. Per Universal 
Approximation Theorem, a FNN with one hidden layer can represent any function ({% cite Cybenko1989 %}), 
although in practice training such a model is very difficult (if not impossible), hence, we usually 
add multiple hidden layers to solve complex problems.

![Neurons forming the input, output, and hidden layers of a multi-layer feedforward neural network](../../images/FFNN.png "Feedforward neural network with a hidden layer. Biases to hidden/output layer neurons are omitted for clarity")

The problem with multi-layer FNN was lack of a learning algorithm, as the Perceptron's learning
algorithm could not be extended to multi-layer FNN. This along with Minsky and Papert highlighting
the limitations of Perceptron resulted in sudden drop in interest in neural networks (referred to 
as *AI winter*). In the 80's the backpropagation algorithm was proposed ({% cite Rumelhart1986 %}), 
which enabled learning in multi-layer FNN, and resulted in a renewed interest in the field.

# Activation functions

There are many activation functions besides the step function used in Perceptron {% cite nwankpaEtAl %}. Figure 4 shows
some of the more common activation functions.

![Table showing the formula, graph, derivative, and range of common activation functions](../../images/FNN_activation_functions.png "Common activation functions (Source: https://en.wikipedia.org/wiki/Activation_function)")

Linear activation function is used in the output layer of a network when we have a regression problem. It does 
not make sense to use it in all layers, as such multi-layer network can be reduced to a single layer network. 
Also, networks with linear activation functions cannot model non-linear relationships between input and output.

Binary step activation function is used in Perceptron. It cannot be used in multi-layers networks as they use 
back propagation learning algorithm, which changes network weights/biases based on derivative of the derivative 
of the activation function, which is zero. Hence, there would no weights/biases updates in back propagation.

Sigmoid activation function can be used both at the output layer and hidden layers of a multilayer network. They 
allow the network to model non-linear realtionships between input and output. The problem with Sigmoid activation
function is that the derivative values away from the origin are very small and quickly approach zero. In a multi
layer network, in order to calculate weight updates in layers closer to the input layer, we use the chain rule 
which requires multiplying multiple Sigmoid derivative values. Multiplying multiple small numbers results in 
a *very* small number, meaning that the weight updates will be minimal and the learning algorithm will be very 
slow. This is known as the *vanishing gradient* problem. In networks with many hidden layers (so called *deep 
networks*), we must use ReLU activation function (Discussed below).

Hyperbolic tangent (or tanh), similar to Sigmoid function, is a soft step function. But its range is between -1 
and 1 (instead of 0 and 1). One benefit of tanh over Sigmoid is that its derivative values are larger, so it
suffers less from the vanishing gradient problem.

Finally, ReLU (Rectified Linear Unit) is an activation function popular is deep neural networks. Since it
does not sufer from vanishing gradient problem, it is preferred to Sigmoid or tanh. Sigmoid or tanh can 
still be used in the output layer of deep networks.      

# Classification/Regression problems

In supervised learning a *training set* is defined as 
$$ {(\boldsymbol{x^{(1)}}, \boldsymbol{y^{(1)}}), ((\boldsymbol{x^{(2)}}, \boldsymbol{y^{(2)}}), ..., ((\boldsymbol{x^{(m)}}, \boldsymbol{y^{(m)}})} $$ {% cite Bagheri %}
and each pair $$ (\boldsymbol{x^{(i)}}, \boldsymbol{y^{(i)}}) $$ is called a *training example*. 
*m* is the number of training examples and $$ \boldsymbol{x^{(i)}} $$ is called *feature vector* 
or *input vector*.  Each element of the vector is called a *feature*. Each $$ \boldsymbol{x^{(i)}} $$
corresponds to a label $$ \boldsymbol{y^{(1)}} $$. We assume there is an unknown function 
$$ \boldsymbol{y} = f(\boldsymbol{x})$$ that maps the feature vectors to labels. The goal of
supervised learning is to use the training set to learn or estimate *f*. We call this estimated
function $$ \hat{f(\boldsymbol{x})} $$. We want $$ \hat{f(\boldsymbol{x})} $$ to be close to 
$$ f(\boldsymbol{x})$$ not only for training set, but for training examples not in training 
set {% cite Bagheri %}.

# The Learning algorithm

In supervised learning, we are given a set of input-output pairs, called the *training set*. Given the training set, 
the learning algorithm (iteratively) adjusts the model parameters, so that the model can accurately map inputs to 
outputs. We usually have another set of input-output pairs, called the *test set*, which is not used by the learning 
algorithm. When the learning algorithm completes, we assess the learned model by providing the test set inputs to 
the model and comparing the model outputs to test set outputs. We need to define a **loss function** to objectively
measure how much the model output is off of the expected output. For classification problems we use the **cross entropy** 
loss function.

$$ L(\boldsymbol{\hat{y^{(j)}}}, \boldsymbol{y^{(j)}}) = - \sum_{i=1}^{n} \boldsymbol{y_{i}^{(j)}}ln(\boldsymbol{\hat{y_{i}^{(j)}}}) $$

The loss function is calculated for each input-output pair in the training set. The average of the calculated loss 
functions for all training set input-output pairs is called the **Cost function**. The goal of the learning algorithm 
is to minimize the cost function. The cost function is a function of network weights and biases of all neurons in all 
layers. 

$$ J(\boldsymbol{W}, \boldsymbol{b}) = - \frac{1}{m} \sum_{j=1}^{m} \sum_{i=1}^{n} \boldsymbol{y_{i}^{(j)}}ln(\boldsymbol{\hat{y_{i}^{(j)}}}) $$

The **backpropagation** learning algorithm {% cite Rumelhart1986 %} iteratively computes the gradient of cost 
function relative to each weight and bias, then updates the weights and biases in the opposite direction of the gradient, 
to find the local minimum.

# Get Data

> ### {% icon hands_on %} Hands-on: Data upload
>
> 1. Create a new history for this tutorial
>
>    {% snippet faqs/galaxy/histories_create_new.md %}
>
> 2. Import the files from [Zenodo](https://zenodo.org/record/4477881) or from the shared data library
>
>    ```
>    https://zenodo.org/record/4477881/files/X_test.tsv
>    https://zenodo.org/record/4477881/files/X_train.tsv
>    https://zenodo.org/record/4477881/files/y_test.tsv
>    https://zenodo.org/record/4477881/files/y_train.tsv
>    ```
>
>    {% snippet faqs/galaxy/datasets_import_via_link.md %}
>
>    {% snippet faqs/galaxy/datasets_import_from_data_library.md %}
>
>
> 3. Rename the datasets as `X_test`, `X_train`, `y_test`, and `y_train` respectively.
>
>    {% snippet faqs/galaxy/datasets_rename.md %}
>
> 4. Check that the datatype of all the four datasets is `tabular`. If not, change the dataset's datatype to tabular.
>
>    {% snippet faqs/galaxy/datasets_change_datatype.md datatype="tabular" %}
>
{: .hands_on}

# Solve a regression problem using Boston housing dataset via FNN in Galaxy

In the section, we define a RNN and train it using IMDB movie reviews training dataset. The goal is to learn a model such that given the
words in a review we can predict whether the review was positive or negative. We then evaluate the trained RNN on the test dataset
and plot the confusion matrix.

### **Create a deep learning model architecture**

> ### {% icon hands_on %} Hands-on: Model config
>
> - {% tool [Create a deep learning model architecture](toolshed.g2.bx.psu.edu/repos/bgruening/keras_model_config/keras_model_config/0.5.0) %}
>    - *"Select keras model type"*: `sequential`
>    - *"input_shape"*: `(500,)`
>    - In *"LAYER"*:
>        - {% icon param-repeat %} *"1: LAYER"*:
>            - *"Choose the type of layer"*: `Embedding -- Embedding`
>                - *"input_dim"*": `10000`
>                - *"output_dim"*": `32`
>        - {% icon param-repeat %} *"2: LAYER"*:
>            - *"Choose the type of layer"*: `Recurrent -- LSTM`
>                - *"units"*": `100`
>        - {% icon param-repeat %} *"3: LAYER"*:
>            - *"Choose the type of layer"*: `Core -- Dense`
>                - *"units"*: `1`
>                - *"Activation function"*: `sigmoid`
>    - Click *"Execute"*
{: .hands_on}

Input is a movie review of size 500 (longer reviews were trimmed and shorter ones padded). Our neural network has 3 layers. The first layer is
an embedding layer, that transforms each review words into a 32 dimensional vector (*output_dim*). We have 10000 unique words in our IMDB dataset
(*input_dim*). The second layer is an *LSTM* layer, which is a type of RNN. Output of the LSTM layer has a size of *100*. The third layer is a
*Dense* layer, which is a fully connected layer (all 100 output neurons in LSTM layer are connected to a single neuron in this layer). It has a
*sigmoid* activation function, that generates an output between 0 and 1. Any output greater than 0.5 is considered a predicted positive review,
and anything less than 0.5 a negative one. The model config can be downloaded as a JSON file.

### **Create a deep learning model**

> ### {% icon hands_on %} Hands-on: Model builder (Optimizer, loss function, and fit parameters)
>
> - {% tool [Create deep learning model](toolshed.g2.bx.psu.edu/repos/bgruening/keras_model_builder/keras_model_builder/0.5.0) %}
>    - *"Choose a building mode"*: `Build a training model`
>    - *"Select the dataset containing model configuration"*: Select the *Keras Model Config* from the previous step.
>    - *"Do classification or regression?"*: `KerasGClassifier`
>    - In *"Compile Parameters"*:
>        - *"Select a loss function"*: `binary_crossentropy`
>        - *"Select an optimizer"*: `Adam - Adam optimizer `
>        - *"Select metrics"*: `acc/accuracy`
>    - In *"Fit Parameters"*:
>        - *"epochs"*: `2`
>        - *"batch_size"*: `128`
>    - Click *"Execute"*
{: .hands_on}

A loss function measures how different the predicted output is versus the expected output. For binary classification problems, we use
*binary cross entropy* as loss function. Epochs is the number of times the whole training data is used to train the model. Setting *epochs* to 2
means each training example in our dataset is used twice to train our model. If we update network weights/biases after all the training data is
feed to the network, the training will be very slow (as we have 25000 training examples in our dataset). To speed up the training, we present
only a subset of the training examples to the network, after which we update the weights/biases. *batch_size* decides the size of this subset.
The model builder can be downloaded as a zip file.

### **Deep learning training and evaluation**

> ### {% icon hands_on %} Hands-on: Training the model
>
> - {% tool [Deep learning training and evaluation](toolshed.g2.bx.psu.edu/repos/bgruening/keras_train_and_eval/keras_train_and_eval/1.0.8.2) %}
>    - *"Select a scheme"*: `Train and Validate`
>    - *"Choose the dataset containing pipeline/estimator object"*: Select the *Keras Model Builder* from the previous step.
>    - *"Select input type:"*: `tabular data`
>        - *"Training samples dataset"*: Select `X_train` dataset
>        - *"Choose how to select data by column:"*: `All columns`
>        - *"Dataset containing class labels or target values"*: Select `y_train` dataset
>        - *"Choose how to select data by column:"*: `All columns`
>    - Click *"Execute"*
>
>
{: .hands_on}

The training step generates 3 datasets. 1) accuracy of the trained model, 2) the trained model, downloadable as a zip file, and 3) the trained
model weights, downloadable as an hdf5 file. These files are needed for prediction in the next step.

### **Model Prediction**

> ### {% icon hands_on %} Hands-on: Testing the model
>
> - {% tool [Model Prediction](toolshed.g2.bx.psu.edu/repos/bgruening/model_prediction/model_prediction/1.0.8.2) %}
>    - *"Choose the dataset containing pipeline/estimator object"* : Select the trained model from the previous step.
>    - *"Choose the dataset containing weights for the estimator above"* : Select the trained model weights from the previous step.
>    - *"Select invocation method"*: `predict`
>    - *"Select input data type for prediction"*: `tabular data`
>    - *"Training samples dataset"*: Select `X_test` dataset
>    - *"Choose how to select data by column:"*: `All columns`
>    - Click *"Execute"*
>
{: .hands_on}

The prediction step generates 1 dataset. It's a file that has predictions (1 or 0 for positive or negative movie reviews) for every review in
the test dataset.

### **Machine Learning Visualization Extension**

> ### {% icon hands_on %} Hands-on: Creating the confusion matrix
>
> - {% tool [Machine Learning Visualization Extension](toolshed.g2.bx.psu.edu/repos/bgruening/ml_visualization_ex/ml_visualization_ex/1.0.8.2) %}
>    - *"Select a plotting type"*: `Confusion matrix for classes`
>    - *"Select dataset containing the true labels"*": `y_test`
>    - *"Choose how to select data by column:"*: `All columns`
>    - *"Select dataset containing the predicted labels"*": Select `Model Prediction` from the previous step
>    - *"Does the dataset contain header:"*: `Yes`
>    - Click *"Execute"*
>
{: .hands_on}

**Confusion Matrix** is a table that describes the performance of a classification model. It lists the number of positive and negative examples
that were correctly classified by the model, True positives (TP) and true negatives (TN), respectively. It also lists the number of examples that
were classified as positive that were actually negative (False positive, FP, or Type I error), and the number of examples that were classified
as negative that were actually positive (False negative, FN, or Type 2 error). Given the confusion matrix, we can calculate **precision** and
**recall** {% cite TatbulEtAl  %}. Precision is the fraction of predicted positives that are true positives (Precision = TP / (TP + FP)). Recall
is the fraction of true positives that are predicted (Recall = TP / (TP + FN)). One way to describe the confusion matrix with just one value is
to use the **F score**, which is the harmonic mean of precision and recall

$$ Precision = \frac{\text{True positives}}{\text{True positives + False positives}} $$

$$ Recall = \frac{\text{True positives}}{\text{True positives + False negatives}} $$

$$ F score = \frac{2 * \text{Precision * Recall}}{\text{Precision + Recall}} $$

![Confusion matrix for our sentiment analysis problem](../../images/ConfusionMatrix.png "Sentiment analysis confusion matrix")

Figure 12 is the resultant confusion matrix for our sentiment analysis problem. The first row in the table represents the *true* 0 (or negative sentiment)
class labels (we have 10,397 + 2,103 = 12,500 reviews with negative sentiment). The second row represents the *true* 1 (or positive sentiment) class labels
(Again, we have 1,281 + 11,219 = 12,500 reviews with positive sentiment). The left column represents the *predicted* negative sentiment class labels (Our RNN
predicted 10,397 + 1,281 = 11,678 reviews as having a negative sentiment). The right column represents the *predicted* positive class labels (Our RNN
predicted 11,219 + 2,103 = 13,322 reviews as having a positive sentiment).Looking at the bottom right cell, we seethat our RNN has correctly predicted 11,219
reviews as having a positive sentiment (True positives). Looking at the top right cell, we see that our RNN has incorrectly predicted 2,103 reviews as having
a positive (False positives). Similarly, looking at the top left cell, we see that our RNN has correctly predicted 10,397 reviews as having negative sentiment
(True negative). Finally, looking at the bottom left cell, we see that our RNN has incorrectly predicted 1,281 reviews as negative (False negative). Given
these numbers we can calculate Precision, Recall, and the F score as follows:

$$ Precision = \frac{\text{True positives}}{\text{True positives + False positives}} = \frac{11,219}{11,219 + 2,102} = 0.84 $$

$$ Recall = \frac{\text{True positives}}{\text{True positives + False negatives}} = \frac{11,219}{11,219 + 1,281} = 0.89 $$

$$ F score = \frac{2 * \text{Precision * Recall}}{\text{Precision + Recall}} = \frac{2 * 0.84 * 0.89}{0.84 + 0.89} = 0.86 $$

# Conclusion
{:.no_toc}

In this tutorial, we briefly reviewed feedforward neural networks, explained how recurrent neural networks are different, and discussed various
RNN input/output and architectures. We also discussed various text representation and preprocessing schemes and used Galaxy to solve a sentiment
classification problem using RNN on IMDB movie reviews dataset.
